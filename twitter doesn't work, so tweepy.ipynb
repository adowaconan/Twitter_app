{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "consumer_key='68qlYXjh8SQWY4n7tjkxoYHhP'\n",
    "consumer_secret='7NTFQF19OyUffhwvPa3w6PflEJLtUxEemD1RJjtnyvM85hGs17'\n",
    "access_token_key='337359768-psJwlyY2MfMt746MrLuiZG87hrGwfxt71yYm092W'\n",
    "access_token_secret='KMbkwAH8UFBoJOvL22BAhFbH0tHG3waMdFDtcRUnthTTY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "import json\n",
    "import datetime as dt\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token_key, access_token_secret)\n",
    " \n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can read our own timeline (i.e. our Twitter homepage) with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for status in tweepy.Cursor(api.home_timeline).items(10):\n",
    "    # Process a single status\n",
    "    print(status.text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#This is a basic listener that just prints received tweets to stdout.\n",
    "class StdOutListener(StreamListener):\n",
    "    def __init__(self):\n",
    "        self.end_time = time.time() + 600 #in seconds\n",
    "        \n",
    "    def on_data(self, data):\n",
    "        if time.time() > self.end_time:\n",
    "            sys.exit()\n",
    "        else:\n",
    "            try:\n",
    "                with open('python.json', 'a') as f:\n",
    "                    f.write(data)\n",
    "                    return True\n",
    "            except BaseException as e:\n",
    "                print(\"Error on_data: %s\" % str(e))\n",
    "            return True\n",
    "\n",
    "    def on_error(self, status):\n",
    "        print(status)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    #This handles Twitter authetification and the connection to Twitter Streaming API\n",
    "    l = StdOutListener()\n",
    "    auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token_key, access_token_secret)\n",
    "    stream = Stream(auth, l)\n",
    "\n",
    "    #This line filter Twitter Streams to capture data by the keywords \n",
    "    stream.filter(track=['python', 'javascript', 'ruby'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_data_path = 'python.json'\n",
    "\n",
    "tweets_data = []\n",
    "tweets_file = open(tweets_data_path, \"r\")\n",
    "for line in tweets_file:\n",
    "    try:\n",
    "        tweet = json.loads(line)\n",
    "        tweets_data.append(tweet)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(tweets_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets['text'] = list(map(lambda tweet:tweet['text'],tweets_data))\n",
    "tweets['lang'] = list(map(lambda tweet: tweet['lang'], tweets_data))\n",
    "tweets['country'] = list(map(lambda tweet: tweet['place']['country'] if tweet['place'] != None else None, tweets_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets_by_lang = tweets['lang'].value_counts()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.tick_params(axis='x', labelsize=15)\n",
    "ax.tick_params(axis='y', labelsize=10)\n",
    "ax.set_xlabel('Languages', fontsize=15)\n",
    "ax.set_ylabel('Number of tweets' , fontsize=15)\n",
    "ax.set_title('Top 5 languages', fontsize=15, fontweight='bold')\n",
    "tweets_by_lang[:5].plot(ax=ax, kind='bar', color='red')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets_by_country = tweets['country'].value_counts()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.tick_params(axis='x', labelsize=15)\n",
    "ax.tick_params(axis='y', labelsize=10)\n",
    "ax.set_xlabel('Countries', fontsize=15)\n",
    "ax.set_ylabel('Number of tweets' , fontsize=15)\n",
    "ax.set_title('Top 5 countries', fontsize=15, fontweight='bold')\n",
    "tweets_by_country[:5].plot(ax=ax, kind='bar', color='blue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_in_text(word, text):\n",
    "    word = word.lower()\n",
    "    text = text.lower()\n",
    "    match = re.search(word, text)\n",
    "    if match:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets['python'] = tweets['text'].apply(lambda tweet: word_in_text('python', tweet))\n",
    "tweets['javascript'] = tweets['text'].apply(lambda tweet: word_in_text('javascript', tweet))\n",
    "tweets['ruby'] = tweets['text'].apply(lambda tweet: word_in_text('ruby', tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(tweets['python'].value_counts()[True])\n",
    "print(tweets['javascript'].value_counts()[True])\n",
    "print(tweets['ruby'].value_counts()[True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prg_langs = ['python', 'javascript', 'ruby']\n",
    "tweets_by_prg_lang = [tweets['python'].value_counts()[True], tweets['javascript'].value_counts()[True], tweets['ruby'].value_counts()[True]]\n",
    "\n",
    "x_pos = list(range(len(prg_langs)))\n",
    "width = 0.8\n",
    "fig, ax = plt.subplots()\n",
    "plt.bar(x_pos, tweets_by_prg_lang, width, alpha=1, color='g')\n",
    "\n",
    "# Setting axis labels and ticks\n",
    "ax.set_ylabel('Number of tweets', fontsize=15)\n",
    "ax.set_title('Ranking: python vs. javascript vs. ruby (Raw data)', fontsize=10, fontweight='bold')\n",
    "ax.set_xticks([p + 0.4 * width for p in x_pos])\n",
    "ax.set_xticklabels(prg_langs)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets['programming'] = tweets['text'].apply(lambda tweet: word_in_text('programming', tweet))\n",
    "tweets['tutorial'] = tweets['text'].apply(lambda tweet: word_in_text('tutorial', tweet))\n",
    "tweets['relevant'] = tweets['text'].apply(lambda tweet: word_in_text('programming', tweet) or word_in_text('tutorial', tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(tweets['programming'].value_counts()[True])\n",
    "print(tweets['tutorial'].value_counts()[True])\n",
    "print(tweets['relevant'].value_counts()[True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(tweets[tweets['relevant'] == True]['python'].value_counts()[True])\n",
    "print(tweets[tweets['relevant'] == True]['javascript'].value_counts()[True])\n",
    "print(list(tweets[tweets['relevant'] == True]['ruby'].value_counts())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets_by_prg_lang = [tweets[tweets['relevant'] == True]['python'].value_counts()[True], \n",
    "                      tweets[tweets['relevant'] == True]['javascript'].value_counts()[True], \n",
    "                      list(tweets[tweets['relevant'] == True]['ruby'].value_counts())[0]]\n",
    "x_pos = list(range(len(prg_langs)))\n",
    "width = 0.8\n",
    "fig, ax = plt.subplots()\n",
    "plt.bar(x_pos, tweets_by_prg_lang, width,alpha=1,color='g')\n",
    "ax.set_ylabel('Number of tweets', fontsize=15)\n",
    "ax.set_title('Ranking: python vs. javascript vs. ruby (Relevant data)', fontsize=10, fontweight='bold')\n",
    "ax.set_xticks([p + 0.4 * width for p in x_pos])\n",
    "ax.set_xticklabels(prg_langs)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting links from the relevants tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_link(text):\n",
    "    regex = r'https?://[^\\s<>\"]+|www\\.[^\\s<>\"]+'\n",
    "    match = re.search(regex, text)\n",
    "    if match:\n",
    "        return match.group()\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets['link'] = tweets['text'].apply(lambda tweet: extract_link(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_relevant = tweets[tweets['relevant'] == True]\n",
    "tweets_relevant_with_link = tweets_relevant[tweets_relevant['link'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(tweets_relevant_with_link[tweets_relevant_with_link['python'] == True]['link'])\n",
    "print(tweets_relevant_with_link[tweets_relevant_with_link['javascript'] == True]['link'])\n",
    "print(tweets_relevant_with_link[tweets_relevant_with_link['ruby'] == True]['link'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get tweets from one user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 202146255294562303\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 142599445538811903\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 106874128690200577\n",
      "...718 tweets downloaded so far\n",
      "getting tweets before 92972361661419519\n",
      "...718 tweets downloaded so far\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# encoding: utf-8\n",
    "\n",
    "import tweepy #https://github.com/tweepy/tweepy\n",
    "import csv\n",
    "\n",
    "#Twitter API credentials\n",
    "consumer_key = consumer_key\n",
    "consumer_secret = consumer_secret\n",
    "access_key = access_token_key\n",
    "access_secret = access_token_secret\n",
    "\n",
    "\n",
    "def get_all_tweets(screen_name):\n",
    "    #Twitter only allows access to a users most recent 3240 tweets with this method\n",
    "\n",
    "    #authorize twitter, initialize tweepy\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_key, access_secret)\n",
    "    api = tweepy.API(auth)\n",
    "\n",
    "    #initialize a list to hold all the tweepy Tweets\n",
    "    alltweets = []\n",
    "\n",
    "    #make initial request for most recent tweets (200 is the maximum allowed count)\n",
    "    new_tweets = api.user_timeline(screen_name = screen_name,count=200)\n",
    "\n",
    "    #save most recent tweets\n",
    "    alltweets.extend(new_tweets)\n",
    "\n",
    "    #save the id of the oldest tweet less one\n",
    "    oldest = alltweets[-1].id - 1\n",
    "\n",
    "    #keep grabbing tweets until there are no tweets left to grab\n",
    "    while len(new_tweets) > 0:\n",
    "        print(\"getting tweets before %s\" % (oldest))\n",
    "\n",
    "        #all subsiquent requests use the max_id param to prevent duplicates\n",
    "        new_tweets = api.user_timeline(screen_name = screen_name,count=200,max_id=oldest)\n",
    "\n",
    "        #save most recent tweets\n",
    "        alltweets.extend(new_tweets)\n",
    "\n",
    "        #update the id of the oldest tweet less one\n",
    "        oldest = alltweets[-1].id - 1\n",
    "\n",
    "        print(\"...%s tweets downloaded so far\" % (len(alltweets)))\n",
    "\n",
    "    #transform the tweepy tweets into a 2D array that will populate the csv\t\n",
    "    outtweets = [[tweet.id_str, tweet.created_at, tweet.text.encode(\"utf-8\")] for tweet in alltweets]\n",
    "\n",
    "    #write the csv\t\n",
    "    with open('%s_tweets.csv' % screen_name, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"id\",\"created_at\",\"text\"])\n",
    "        writer.writerows(outtweets)\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #pass in the username of the account you want to download\n",
    "    get_all_tweets(\"adowa_conan\")# @names\n",
    "    print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 202146255294562303\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 142599445538811903\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 106874128690200577\n",
      "...718 tweets downloaded so far\n",
      "getting tweets before 92972361661419519\n",
      "...718 tweets downloaded so far\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "#Twitter API credentials\n",
    "consumer_key = consumer_key\n",
    "consumer_secret = consumer_secret\n",
    "access_key = access_token_key\n",
    "access_secret = access_token_secret\n",
    "\n",
    "\n",
    "def get_all_tweets(screen_name):\n",
    "    #Twitter only allows access to a users most recent 3240 tweets with this method\n",
    "\n",
    "    #authorize twitter, initialize tweepy\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_key, access_secret)\n",
    "    api = tweepy.API(auth)\n",
    "\n",
    "    #initialize a list to hold all the tweepy Tweets\n",
    "    alltweets = []\n",
    "\n",
    "    #make initial request for most recent tweets (200 is the maximum allowed count)\n",
    "    new_tweets = api.user_timeline(screen_name = screen_name,count=200)\n",
    "\n",
    "    #save most recent tweets\n",
    "    alltweets.extend(new_tweets)\n",
    "\n",
    "    #save the id of the oldest tweet less one\n",
    "    oldest = alltweets[-1].id - 1\n",
    "\n",
    "    #keep grabbing tweets until there are no tweets left to grab\n",
    "    while len(new_tweets) > 0:\n",
    "        print(\"getting tweets before %s\" % (oldest))\n",
    "\n",
    "        #all subsiquent requests use the max_id param to prevent duplicates\n",
    "        new_tweets = api.user_timeline(screen_name = screen_name,count=200,max_id=oldest)\n",
    "\n",
    "        #save most recent tweets\n",
    "        alltweets.extend(new_tweets)\n",
    "\n",
    "        #update the id of the oldest tweet less one\n",
    "        oldest = alltweets[-1].id - 1\n",
    "\n",
    "        print(\"...%s tweets downloaded so far\" % (len(alltweets)))\n",
    "    \n",
    "    #transform the tweepy tweets into a 2D array that will populate the csv\t\n",
    "    with open('%s_tweets.json' % screen_name, 'w') as f:\n",
    "        json.dump([status._json for status in alltweets],f)\n",
    "    \n",
    "\n",
    "    pass\n",
    "    #return alltweets\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #pass in the username of the account you want to download\n",
    "    get_all_tweets(\"adowa_conan\")# @names\n",
    "    print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "screen_name = 'realDonaldTrump'\n",
    "get_all_tweets(screen_name)\n",
    "print('finished')\n",
    "tweets_data_path = '%s_tweets.json' % screen_name\n",
    "\n",
    "tweets_data = []\n",
    "tweets_file = open(tweets_data_path, \"r\")\n",
    "for line in tweets_file:\n",
    "\n",
    "    tweet = json.loads(line)\n",
    "    tweets_data.append(tweet)\n",
    "\n",
    "\n",
    "tweets_data=tweets_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Where was all the outrage from Democrats and t...</td>\n",
       "      <td>Mon Jan 30 14:23:49 +0000 2017</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have made my decision on who I will nominate...</td>\n",
       "      <td>Mon Jan 30 13:43:25 +0000 2017</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If the ban were announced with a one week noti...</td>\n",
       "      <td>Mon Jan 30 13:31:00 +0000 2017</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>There is nothing nice about searching for terr...</td>\n",
       "      <td>Mon Jan 30 12:27:05 +0000 2017</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>protesters and the tears of Senator Schumer. S...</td>\n",
       "      <td>Mon Jan 30 12:20:49 +0000 2017</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Where was all the outrage from Democrats and t...   \n",
       "1  I have made my decision on who I will nominate...   \n",
       "2  If the ban were announced with a one week noti...   \n",
       "3  There is nothing nice about searching for terr...   \n",
       "4  protesters and the tears of Senator Schumer. S...   \n",
       "\n",
       "                             time  \\\n",
       "0  Mon Jan 30 14:23:49 +0000 2017   \n",
       "1  Mon Jan 30 13:43:25 +0000 2017   \n",
       "2  Mon Jan 30 13:31:00 +0000 2017   \n",
       "3  Mon Jan 30 12:27:05 +0000 2017   \n",
       "4  Mon Jan 30 12:20:49 +0000 2017   \n",
       "\n",
       "                                              source  \n",
       "0  <a href=\"http://twitter.com/download/iphone\" r...  \n",
       "1  <a href=\"http://twitter.com/download/android\" ...  \n",
       "2  <a href=\"http://twitter.com/download/android\" ...  \n",
       "3  <a href=\"http://twitter.com/download/android\" ...  \n",
       "4  <a href=\"http://twitter.com/download/android\" ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets=pd.DataFrame()\n",
    "tweets['text'] = list(map(lambda tweet:tweet['text'],tweets_data))\n",
    "tweets['time'] = list(map(lambda tweet:tweet['created_at'],tweets_data))\n",
    "tweets['source']=list(map(lambda tweet:tweet['source'],tweets_data))\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mon', 'Jan', '30', '14:23:49', '+0000', '2017']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.time[0].split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File not open for reading",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-b1c48cbcbd3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mscreen_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'realDonaldTrump'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%s_tweets.json'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mscreen_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtweets_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Anaconda2\\lib\\json\\__init__.pyc\u001b[0m in \u001b[0;36mload\u001b[1;34m(fp, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m     \"\"\"\n\u001b[1;32m--> 287\u001b[1;33m     return loads(fp.read(),\n\u001b[0m\u001b[0;32m    288\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: File not open for reading"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "screen_name = 'realDonaldTrump'\n",
    "with open('%s_tweets.json' % screen_name, 'w') as f:\n",
    "    tweets_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-bacd0e0f09a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: I/O operation on closed file"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
